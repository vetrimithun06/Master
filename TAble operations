package pack1
import org.apache.spark._

import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.Row
import org.apache.spark.sql.types._
import org.apache.spark.sql.Row
import org.apache.spark.sql.functions._

import org.apache.spark._
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.Row
import org.apache.spark.sql.types._
import org.apache.spark.sql.Row
import org.apache.spark.sql.functions._


object obj29TableOperations {


  def main (args:Array[String]):Unit= {
   println("=========Session 29 Started ============")
			println
			val conf = new SparkConf().setAppName("ES").setMaster("local[*]")

			val sc = new SparkContext(conf)
			sc.setLogLevel("ERROR")

			val spark = SparkSession.builder().getOrCreate()
			import spark.implicits._

   println("=========Country Data============")
   //Spark READ XML file 
   //Add additonal jar and give .option("rowTag","book")
   //without option - table will not been shown.val xmlfile = spark.read.format("xml").load("file:///C:/Users/DELL G15/OneDrive/Datas for Task/Video 27/book.xml")
	val dtdf = spark
			          .read
			          .format("csv")
			          .option("header","true")
			          .load("file:///D:/DELL G15/workspace/Session 29 DSL Operations/dt.txt")
      dtdf.show() 
println("=========Filter Data using AND ============")
			val fildf = dtdf.filter(
			                    col("category")==="Exercise"
			                   &&
			                    col("spendby")==="cash"
			                  
			                    )
			
			fildf.show()
println("=========Filter Data using  OR ============")
			val fildf1 = dtdf.filter(
			                    col("category")==="E%"
			                    ||
			                    col("spendby")==="cash"
			                    )
			fildf1.show()
 println("=========Full Handson============")
  println("=========Full Handson using dtdf============")
 
			dtdf.show()
			println
			println("=========select command and filter================")
			println
			val sdf = dtdf.filter( col("category")==="Exercise").select("id","tdate")
			sdf.show()
			
		//	val sdf2 = dtdf.withColumn("id",filter(("category") equals "Exercise") )
			    
			//sdf2.show()
			println
			

//for filtering multivalues inside one column use category
//col used for filtering 2 diff columns and not for multivalues inside one columns
//Filter COLUMN equals Gymnastics
			println("=========filter inside one column================")
			println
			val fdf = dtdf.filter(col("category")==="Gymnastics")
			fdf.show()
			println
			
			
			println("=========MultiColumn Filter (Filtering datas in 2 columns)================")
			println

			val adf = dtdf.filter(

					col("category")==="Gymnastics"
					&&
					col("spendby")==="cash"

					)

			adf.show()

			println
			println("=========MultiColumn Filter with or operator================")
			println
			val odf = dtdf.filter(

					col("category")==="Gymnastics"
					||
					col("spendby")==="cash"

					)
			odf.show()
			println
			
//for filtering multivalues inside one/same column use "category" and "isin"
//"isin" is used for multivalue filter inside one column
			println("=========multi value================")
			println

			val mdf1 = dtdf.filter(col("category") isin ("Gymnastics","Exercise"))
			mdf1.show()
			println
			
//Print "Product" contains Gymnastics , contains means like operations
val fdf2 = dtdf.filter(col("product") like "%Gymnastics%") 
//percentage symbol means proGymnasticspro prefix or suffix may be anything Gymnastics should exist


			println("=========like operator================")
			println
			val cdf = dtdf.filter(col("product") like "%Gymnastics%")  
//is different from equals as equals means exact and like/contains means similar
//or .contains can be used val cdf = dtdf.filter (col("product").contains("%Gymnastics%") )			
			cdf.show()
			println
	
//FIlter id column is null	
//use "isNull"
			println("=========null filter================")
			println
			val ndf = dtdf.filter(col("id").isNull)
			ndf.show()
			println
//FIlter id column is not null		
			println("=========not null filter================")
			println
			val nndf = dtdf.filter(
			!  (  col("id").isNull  )
			)
			nndf.show()
							println("=========selectExpr Filter================")
			
      dtdf.show() 
      
			val expression = dtdf.selectExpr(
"id",
"split(tdate,'-')[2] as year",
"amount",
"category",
"product",
"spendby"
)			
expression.show()
 
			
  }
}
